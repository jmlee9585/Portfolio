# -*- coding: utf-8 -*-
"""A system for generating digital media contents based on data augmentation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nFLafgKIl6ycs_0jpV6kMfer805nLdXZ

# 1. Google Mount
"""

from google.colab import drive
import shutil

# # 기존 마운트 해제
# drive.flush_and_unmount()

# # 디렉토리 초기화 (파일 강제 삭제)
# shutil.rmtree('/content/drive', ignore_errors=True)

# 구글 드라이브 마운트
from google.colab import drive
drive.mount('/content/drive')

"""# 2. Version, Dependencies"""

!pip install torch==2.7.0 torchvision==0.22.0+cu126 torchaudio==2.7.0 --index-url https://download.pytorch.org/whl/cu126
!pip install --no-deps diffusers huggingface_hub transformers accelerate datasets fsspec xformers pytorch-fid

!python -m xformers.info

"""# 3. Preprocessing (Resizing, tif to png)"""

from PIL import Image
import os
import math

def resize_with_padding(img_path, output_size=1024):
    img = Image.open(img_path).convert("RGB")
    width, height = img.size
    ratio = min(output_size/width, output_size/height)
    new_w = math.floor(width * ratio)
    new_h = math.floor(height * ratio)
    img = img.resize((new_w, new_h), Image.LANCZOS)
    new_img = Image.new("RGB", (output_size, output_size), (255, 255, 255))
    new_img.paste(img, ((output_size - new_w)//2, (output_size - new_h)//2))
    return new_img

input_dir = "/content/drive/MyDrive/88_IAU_Constellations"
output_dir = "/content/drive/MyDrive/88_IAU_Constellations/resized_images/class1"
os.makedirs(output_dir, exist_ok=True)

image_files = [f for f in os.listdir(input_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.tif'))]
image_files.sort()  # 정렬(선택)

for idx, filename in enumerate(image_files):
    img_path = os.path.join(input_dir, filename)
    resized_img = resize_with_padding(img_path)
    new_filename = f"image_{idx:04d}.png"  # 항상 PNG로 저장
    resized_img.save(os.path.join(output_dir, new_filename))

"""# 4. Importing Packages"""

import torch, torchvision, torchaudio, diffusers, huggingface_hub, transformers, accelerate, datasets, fsspec, os

print(torch.cuda.is_available())
print(f"PyTorch 버전: {torch.__version__}")
print(f"Diffusers 버전: {diffusers.__version__}")
print(f"CUDA 버전: {torch.version.cuda}")
print(f"GPU 지원 여부: {torch.cuda.is_available()}")

"""# 5. Stable Diffusion Default Model"""

from diffusers import StableDiffusionPipeline
import torch
import os

os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'

model_id = "runwayml/stable-diffusion-v1-5"

pipe = StableDiffusionPipeline.from_pretrained(
    model_id,
    torch_dtype=torch.float32
)
pipe.to("cuda")

"""# 6. Data Load and Agumentation"""

from torchvision import transforms
from datasets import load_dataset

# 특허와 달리 실시간 증강 기법을 적용함 (특허의 직접 증강 방법은 아래 참고)
# 1. 증강(augmentation) transform 정의
train_transform = transforms.Compose([
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(20),
    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1)
    # 필요에 따라 추가 증강 가능
])

# 2. 데이터셋 로드
data_dir_path = "/content/drive/MyDrive/88_IAU_Constellations/resized_images"
dataset = load_dataset("imagefolder", data_dir=data_dir_path)

# 3. 텍스트 프롬프트 매핑 ('constellation abstract art'로 모든 이미지에 일괄 할당)
prompt = "constellation abstract art"
def add_prompt(example):
    example["text"] = prompt
    return example
dataset["train"] = dataset["train"].map(add_prompt)

# 4. 실시간 증강(transform) 적용
def apply_augmentation(examples):
    examples["image"] = [train_transform(img) for img in examples["image"]]
    return examples

dataset["train"].set_transform(apply_augmentation)

# Data Agumentation

from PIL import Image, ImageEnhance, ImageOps

# 이미지 불러오기 (파일 경로를 실제 파일명으로 변경)
img = Image.open('/content/drive/MyDrive/88_IAU_Constellations/Andromeda.tif')

# 1. Flip (좌우반전/상하반전)
horizontal_flip = ImageOps.mirror(img)    # 좌우 반전
vertical_flip = ImageOps.flip(img)        # 상하 반전

# 2. Grayscale (흑백 변환)
grayscale = ImageOps.grayscale(img)

# 3. Saturation (채도 조절)
saturation_up = ImageEnhance.Color(img).enhance(1.5)    # 채도 증가
saturation_down = ImageEnhance.Color(img).enhance(0.5)  # 채도 감소

# 4. Brightness (명도 조절)
brightness_up = ImageEnhance.Brightness(img).enhance(1.5)    # 명도 증가
brightness_down = ImageEnhance.Brightness(img).enhance(0.5)  # 명도 감소

# 5. Rotation (회전)
rotation_45 = img.rotate(45)           # 시계방향 45도 회전
rotation_neg45 = img.rotate(-45)       # 반시계방향 45도 회전

# 이미지 저장 전 RGBA → RGB로 변환
def save_as_jpeg(img, file_name):
    if img.mode == 'RGBA':
        img = img.convert('RGB')
    img.save(file_name, format='JPEG')

# 증강 후 저장
save_as_jpeg(horizontal_flip, '/content/drive/MyDrive/88_IAU_Constellations/Agumentation/horizontal_flip.jpg')
save_as_jpeg(vertical_flip, '/content/drive/MyDrive/88_IAU_Constellations/Agumentation/vertical_flip.jpg')
save_as_jpeg(grayscale, '/content/drive/MyDrive/88_IAU_Constellations/Agumentation/grayscale.jpg')
save_as_jpeg(saturation_up, '/content/drive/MyDrive/88_IAU_Constellations/Agumentation/saturation_up.jpg')
save_as_jpeg(saturation_down, '/content/drive/MyDrive/88_IAU_Constellations/Agumentation/saturation_down.jpg')
save_as_jpeg(brightness_up, '/content/drive/MyDrive/88_IAU_Constellations/Agumentation/brightness_up.jpg')
save_as_jpeg(brightness_down, '/content/drive/MyDrive/88_IAU_Constellations/Agumentation/brightness_down.jpg')
save_as_jpeg(rotation_45, '/content/drive/MyDrive/88_IAU_Constellations/Agumentation/rotation_45.jpg')
save_as_jpeg(rotation_neg45, '/content/drive/MyDrive/88_IAU_Constellations/Agumentation/rotation_neg45.jpg')

"""# 7. Fine Tuining"""

import torch
from torch.utils.data import DataLoader
from torchvision import transforms
from tqdm.auto import tqdm
from torch.optim.lr_scheduler import CosineAnnealingLR

# 1. 학습 파라미터 설정
training_args = {
    "num_train_epochs": 50,
    "learning_rate": 1e-5,
    "train_batch_size": 2,
    "gradient_accumulation_steps": 4,
    "mixed_precision": "fp16",
    "max_train_steps": 1000,
    "lr_scheduler": "cosine"
}

# 2. 데이터셋 변환
to_tensor = transforms.ToTensor()

def flatten_and_to_tensor(img):
    # 리스트가 중첩되어 있다면 flatten
    while isinstance(img, list):
        img = img[0]
    if isinstance(img, torch.Tensor):
        return img
    if isinstance(img, (int, float)):
        print("경고: 이미지가 아닌 값이 들어왔습니다:", img)
        return None  # 혹은 torch.zeros(...) 등으로 대체
    return to_tensor(img)

def set_transform_fn(examples):
    images = []
    for img in examples["image"]:
        tensor = flatten_and_to_tensor(img)
        if tensor is not None:
            images.append(tensor)
    examples["image"] = images
    return examples

dataset["train"].set_transform(set_transform_fn)

# 3. DataLoader 설정
def collate_fn(batch):
    images = [item["image"] for item in batch]
    images = torch.stack(images).to(pipe.device)
    return {"image": images}

train_dataloader = DataLoader(
    dataset["train"],
    batch_size=training_args["train_batch_size"],
    shuffle=True,
    collate_fn=collate_fn,
    num_workers=0
)

# 4. 옵티마이저 & 스케줄러
optimizer = torch.optim.AdamW(pipe.unet.parameters(), lr=training_args["learning_rate"])
scheduler = CosineAnnealingLR(optimizer, T_max=training_args["max_train_steps"])

# 5. 혼합 정밀도 설정
scaler = torch.amp.GradScaler(enabled=(training_args["mixed_precision"] == "fp16"))

"""# 8. Architecture"""

# 학습 전 캐시 정리
torch.cuda.empty_cache()

print(f"현재 할당된 메모리: {torch.cuda.memory_allocated() / 1024**3:.2f} GB")
print(f"최대 할당된 메모리: {torch.cuda.max_memory_allocated() / 1024**3:.2f} GB")
print(f"예약된 메모리: {torch.cuda.memory_reserved() / 1024**3:.2f} GB")

# 6. 학습 루프 설정
pipe.unet.train()
pipe.text_encoder.eval()
global_step = 0
pipe.enable_vae_slicing()
pipe.vae.to(dtype=torch.float32)
pipe.enable_xformers_memory_efficient_attention()

# --- LoRA 설정 추가 (학습 루프 시작 전) ---
from peft import LoraConfig, get_peft_model

lora_config = LoraConfig(
    r=64,
    lora_alpha=32,
    target_modules=["to_q", "to_k", "to_v", "to_out.0"],
    lora_dropout=0.0,
)

# LoRA 적용
pipe.unet = get_peft_model(pipe.unet, lora_config)

# 기존 파라미터 freeze, LoRA만 학습
for param in pipe.unet.parameters():
    param.requires_grad = False
for name, param in pipe.unet.named_parameters():
    if "lora_" in name:
        param.requires_grad = True

optimizer = torch.optim.AdamW(
    filter(lambda p: p.requires_grad, pipe.unet.parameters()),
    lr=training_args["learning_rate"]
)
scheduler = CosineAnnealingLR(optimizer, T_max=training_args["max_train_steps"])
scaler = torch.amp.GradScaler(enabled=(training_args["mixed_precision"] == "fp16"))

# 학습 루프 시작
for epoch in tqdm(range(training_args["num_train_epochs"]), desc="Epochs"):
    for batch in tqdm(train_dataloader, desc="Batches"):
        # 1. 그래디언트 초기화 (autocast 블록 밖에서)
        optimizer.zero_grad()

        # 2. 순전파 + 역전파 (autocast 블록 내에서)
        with torch.amp.autocast(device_type='cuda', dtype=torch.float32, enabled=True):
            images = batch["image"].to("cuda", dtype=torch.float32)

            # VAE 인코딩 (no_grad 필수)
            with torch.no_grad():
                latents = pipe.vae.encode(images).latent_dist.sample()
                latents = latents * 0.18215

            # 노이즈 생성
            noise = torch.randn_like(latents)
            timesteps = torch.randint(
                0, pipe.scheduler.config.num_train_timesteps,
                (latents.shape[0],), device=latents.device
            )
            noisy_latents = pipe.scheduler.add_noise(latents, noise, timesteps)

            # 텍스트 임베딩
            empty_prompt = [""] * len(images)
            text_inputs = pipe.tokenizer(
                empty_prompt,
                padding="max_length",
                max_length=pipe.tokenizer.model_max_length,
                truncation=True,
                return_tensors="pt"
            ).to("cuda")
            encoder_hidden_states = pipe.text_encoder(text_inputs.input_ids)[0]

            # UNet 예측 및 손실 계산
            model_pred = pipe.unet(noisy_latents, timesteps, encoder_hidden_states).sample
            loss = torch.nn.functional.mse_loss(model_pred, noise)

        # 3. 역전파 (autocast 블록 밖에서)
        scaler.scale(loss).backward()

        # 4. Gradient Accumulation
        if (global_step + 1) % training_args["gradient_accumulation_steps"] == 0:
            torch.nn.utils.clip_grad_norm_(pipe.unet.parameters(), 1.0)
            scaler.step(optimizer)
            scaler.update()
            scheduler.step()

        global_step += 1

"""# 9. Save and Load the Model"""

# 1. 모델 저장하기
output_dir = "/content/drive/MyDrive/88_IAU_Constellations/Constellation"
pipe.unet = pipe.unet.merge_and_unload()
pipe.save_pretrained(output_dir)

if not os.path.exists(output_dir):
    print("저장 디렉토리가 존재하지 않습니다. 모델이 제대로 저장되지 않았습니다.")
else:
    print("저장 디렉토리 내 파일 목록:", os.listdir(output_dir))

# 2. 저장한 모델 불러오기
from diffusers import StableDiffusionPipeline

output_dir = "/content/drive/MyDrive/88_IAU_Constellations/Constellation"

# pipe가 StableDiffusionPipeline 인스턴스인지 반드시 확인
pipe = StableDiffusionPipeline(
    vae=pipe.vae,
    text_encoder=pipe.text_encoder,
    tokenizer=pipe.tokenizer,
    unet=pipe.unet,
    scheduler=pipe.scheduler,
    safety_checker=pipe.safety_checker,
    feature_extractor=pipe.feature_extractor,
    # image_encoder는 명시하지 않음!
)
pipe = pipe.to("cuda")

"""# 10. Test"""

# 3. 이미지 생성 테스트
prompt = "A mesmerizing abstract constellation floating in deep cosmic blues and purples, \
stars and swirling nebulae forming intricate patterns across a vast universe"
negative_prompt = ""
image = pipe(prompt, negative_prompt=negative_prompt, guidance_scale=9.0,  # 프롬프트에 더 민감하게
    num_inference_steps=50, height=1080, width=1920).images[0]

from PIL import Image
from IPython.display import display

# image가 PIL.Image 객체가 아니라면 변환 필요
if not isinstance(image, Image.Image):
    image.save("temp.png")  # 임시 파일로 저장
    image = Image.open("temp.png")

# 이미지 크기 출력
print(f"이미지 크기: {image.size} (너비 x 높이)")

# 이미지 표시
display(image)  # 이미지 출력 (Colab에서는 display(image) 또는 image.save("output.png") 권장)

# 4. 이미지 저장

import os
from pathlib import Path

# 저장할 디렉토리 경로
save_dir = Path("/content/drive/MyDrive/88_IAU_Constellations/Constellation/Output")
save_dir.mkdir(parents=True, exist_ok=True)  # 폴더가 없으면 생성

# 디렉토리 내 output_*.png 파일 목록 확인
existing_files = list(save_dir.glob("output_*.png"))

# 파일명에서 숫자 추출
existing_indices = []
for f in existing_files:
    stem = f.stem  # 예: "output_0001"
    parts = stem.split('_')
    if len(parts) == 2 and parts[1].isdigit():
        existing_indices.append(int(parts[1]))

# 다음 저장할 파일 번호 계산
next_index = max(existing_indices) + 1 if existing_indices else 0

# 저장할 파일명
next_filename = save_dir / f"output_{next_index:04d}.png"

# 이미지 저장 (image는 생성된 PIL.Image 객체)
image.save(next_filename)

"""# 11. Evaluate"""

from pytorch_fid import fid_score

def evaluate_fid(original_dir, generated_dir):
    fid = fid_score.calculate_fid_given_paths(
        [original_dir, generated_dir],
        batch_size=8,
        device='cuda',
        dims=2048
    )
    print(f"FID 값: {fid}")
    return fid

# 실제 평가 실행
original_dir = "/content/drive/MyDrive/88_IAU_Constellations/resized_images/class1"
generated_dir = "/content/drive/MyDrive/88_IAU_Constellations/Constellation/Output"

fid = evaluate_fid(original_dir, generated_dir)